{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75ce1a52",
   "metadata": {},
   "source": [
    "# Resnet 50 on webcam with opencv on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41228cdb",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade9c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import cv2.cuda as cv2cuda\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd1f55f",
   "metadata": {},
   "source": [
    "## Check opencv cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53a9c46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** CUDA Device Query (Runtime API) version (CUDART static linking) *** \n",
      "\n",
      "Device count: 1\n",
      "\n",
      "Device 0: \"Quadro T1000\"\n",
      "  CUDA Driver Version / Runtime Version          11.80 / 10.20\n",
      "  CUDA Capability Major/Minor version number:    7.5\n",
      "  Total amount of global memory:                 3914 MBytes (4104454144 bytes)\n",
      "  GPU Clock Speed:                               1.53 GHz\n",
      "  Max Texture Dimension Size (x,y,z)             1D=(131072), 2D=(131072,65536), 3D=(16384,16384,16384)\n",
      "  Max Layered Texture Size (dim) x layers        1D=(32768) x 2048, 2D=(32768,32768) x 2048\n",
      "  Total amount of constant memory:               65536 bytes\n",
      "  Total amount of shared memory per block:       49152 bytes\n",
      "  Total number of registers available per block: 65536\n",
      "  Warp size:                                     32\n",
      "  Maximum number of threads per block:           1024\n",
      "  Maximum sizes of each dimension of a block:    1024 x 1024 x 64\n",
      "  Maximum sizes of each dimension of a grid:     2147483647 x 65535 x 65535\n",
      "  Maximum memory pitch:                          2147483647 bytes\n",
      "  Texture alignment:                             512 bytes\n",
      "  Concurrent copy and execution:                 Yes with 3 copy engine(s)\n",
      "  Run time limit on kernels:                     Yes\n",
      "  Integrated GPU sharing Host Memory:            No\n",
      "  Support host page-locked memory mapping:       Yes\n",
      "  Concurrent kernel execution:                   Yes\n",
      "  Alignment requirement for Surfaces:            Yes\n",
      "  Device has ECC support enabled:                No\n",
      "  Device is using TCC driver mode:               No\n",
      "  Device supports Unified Addressing (UVA):      Yes\n",
      "  Device PCI Bus ID / PCI location ID:           1 / 0\n",
      "  Compute Mode:\n",
      "      Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) \n",
      "\n",
      "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version  = 11.80, CUDA Runtime Version = 10.20, NumDevs = 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv2cuda.printCudaDeviceInfo(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31651185",
   "metadata": {},
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "632cc7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet50(weights=torchvision.models.ResNet50_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c75553",
   "metadata": {},
   "source": [
    "## Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0736fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict with ImageNet labels\n",
    "with open('imagenet_labels.txt') as f:\n",
    "    labels = eval(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1ae69c",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eed8e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "CAPTURE_WIDTH = 640\n",
    "CAPTURE_HEIGHT = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4afc4fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0] global /opt/opencv-4.5.0/modules/videoio/src/cap_gstreamer.cpp (935) open OpenCV | GStreamer warning: Cannot query video position: status=0, value=-1, duration=-1\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.0) /opt/opencv-4.5.0/modules/core/src/cuda/gpu_mat.cu:116: error: (-217:Gpu API call) all CUDA-capable devices are busy or unavailable in function 'allocate'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m ret, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     20\u001b[0m t_frame \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 21\u001b[0m \u001b[43mgpu_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[1;32m     23\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage resolution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mframe\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.0) /opt/opencv-4.5.0/modules/core/src/cuda/gpu_mat.cu:116: error: (-217:Gpu API call) all CUDA-capable devices are busy or unavailable in function 'allocate'\n"
     ]
    }
   ],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Open webcam and start inference\n",
    "cap = cv2.VideoCapture(0)\n",
    "gpu_frame = cv2.cuda_GpuMat()\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, CAPTURE_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, CAPTURE_HEIGHT)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 0.5\n",
    "fontColor = (10,10,10)\n",
    "lineThickness= 1\n",
    "lineType = cv2.LINE_AA\n",
    "pos = 30\n",
    "do_preprocess = True\n",
    "\n",
    "while True:\n",
    "    t0 = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    t_frame = time.time()\n",
    "    gpu_frame.upload(frame)\n",
    "    pos = 30\n",
    "    string = f\"Image resolution: {frame.shape}\"\n",
    "    cv2.putText(frame, string, (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    print(string, end='')\n",
    "    string = f\"Open frame time: {((t_frame - t0)*1000):.2f} ms\"\n",
    "    cv2.putText(frame, string, (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    print('\\t'+string, end='')\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # Preprocess image\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    t_color = time.time()\n",
    "    string = f\"Color transformation: {((t_color - t_frame)*1000):.2f} ms\"\n",
    "    cv2.putText(frame, string, (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    print('\\t'+string, end='')\n",
    "#    # img = cv2.resize(img, (224, 224))\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img = torch.from_numpy(img)\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        outputs = model(img)\n",
    "        end = time.time()\n",
    "        string = f\"Inference time: {((end - start)*1000):.2f} ms\"\n",
    "        cv2.putText(frame, string, (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "        pos += 20\n",
    "        print('\\t'+string, end='')\n",
    "\n",
    "    # Postprocess\n",
    "    outputs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    outputs = outputs.squeeze(0)\n",
    "    outputs = outputs.tolist()\n",
    "    idx = outputs.index(max(outputs))\n",
    "    string = f\"Predicted: {idx}-{labels[idx]}\"\n",
    "    cv2.putText(frame, string, (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    print('\\t'+string, end='')\n",
    "\n",
    "    # FPS\n",
    "    t = time.time() - t0\n",
    "    string = f\"FPS: {1/t:.2f}\"\n",
    "    cv2.putText(frame, string, (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    print('\\t'+string, end='')\n",
    "\n",
    "    # Image shape\n",
    "    string = f\"Image shape: {img.shape}\"\n",
    "    cv2.putText(frame, string, (10, pos), font, fontScale, fontColor, lineThickness, lineType)\n",
    "    pos += 20\n",
    "    print('\\t'+string, end='')\n",
    "    print()\n",
    "\n",
    "    # Display\n",
    "#     cv2.imshow(\"frame\", frame)\n",
    "#     if cv2.waitKey(1) == ord('q'):\n",
    "#         break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8f46493",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.0) /opt/opencv-4.5.0/modules/core/include/opencv2/core/private.cuda.hpp:112: error: (-213:The function/feature is not implemented) The called functionality is disabled for current build or platform in function 'throw_no_cuda'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudacodec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateVideoReader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.0) /opt/opencv-4.5.0/modules/core/include/opencv2/core/private.cuda.hpp:112: error: (-213:The function/feature is not implemented) The called functionality is disabled for current build or platform in function 'throw_no_cuda'\n"
     ]
    }
   ],
   "source": [
    "cv2.cudacodec.createVideoReader(\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06ec0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97d8b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.cudacodec."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
