{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalar tensorrt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Ir a la página de [descargas](https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#downloading) donde se explica todo\n",
    " * Ir a la página de [tensorrt](https://developer.nvidia.com/tensorrt) para descargarlo\n",
    " * Darle a *Get started*, hacer logging y por último a *Download now*\n",
    " * Seleccionar la versión, en mi caso elijo la última, `TensorRT 8`\n",
    " * Aceptar los términos y condiciones de Nvidia y seleccionar una versión de `TensorRT 8`. La diferencia entre `EA` (early access) y `GA` (general availability) es que GA es la versión estable. Así que en mi caso elijo la última estable, `TensorRT 8.4 GA Update 2`\n",
    " * Como tengo *Ubuntu 20.04* y *cuda 11.6* elijo la versión `TensorRT 8.4 GA Update 2 for Ubuntu 20.04 and CUDA 11.0, 11.1, 11.2, 11.3, 11.4, 11.5, 11.6 and 11.7 DEB local repo Package`. Esto me descarga el archivo\n",
    "  * `nv-tensorrt-repo-ubuntu2004-cuda11.6-trt8.4.3.1-ga-20220813_1-1_amd64.deb`\n",
    " * Esribir en la terminal \n",
    "   ``` bash\n",
    "    $ os=\"ubuntuxx04\"\n",
    "    $ tag=\"cudax.x-trt8.x.x.x-ga-yyyymmdd\"\n",
    "   ```\n",
    "   Donde `x`, `y`, `m` y `d` son la versión, día, mes y año del archivo, en mi caso escribo\n",
    "   ``` bash\n",
    "    $ os=\"ubuntu2004\"\n",
    "    $ tag=\"cuda11.6-trt8.4.3.1-ga-20220813\"\n",
    "   ```\n",
    " * A continuación introducir por la terminal\n",
    "   ``` bash\n",
    "    $ sudo dpkg -i nv-tensorrt-repo-${os}-${tag}_1-1_amd64.deb\n",
    "    $ sudo apt-key add /var/nv-tensorrt-repo-${os}-${tag}/*.pub\n",
    "   ```\n",
    " * Actualizar\n",
    "   ``` bash\n",
    "    $ sudo apt update\n",
    "   ```\n",
    " * Instalar TensorRT\n",
    "   ``` bash\n",
    "    $ sudo apt install tensorrt\n",
    "   ```\n",
    " * Como se va a usar Python 3, instalar numpy y python3-libnvinfer-dev\n",
    "  * Para instalar Numpy, si se tiene conda, instalar mediante\n",
    "    ``` bash\n",
    "     $ conda install numpy\n",
    "    ```\n",
    "  * Si no se tiene conda, instalar mediante pip con\n",
    "    ``` bash\n",
    "     $ pip install numpy\n",
    "    ```\n",
    "  * Para instalar python3-libnvinfer-dev introducir\n",
    "    ``` bash\n",
    "     $ pip install numpy\n",
    "    ```\n",
    " * Como se va a querer usar onnx instalarlo mediante\n",
    "   ``` bash\n",
    "    $ pip install onnx\n",
    "    $ sudo apt install onnx-graphsurgeon\n",
    "   ```\n",
    " * Verificar la instalación mediante\n",
    "   ``` bash\n",
    "    $ sudo dpkg -l | grep TensorRT\n",
    "   ```\n",
    "   Debería salir algo como\n",
    "   ``` bash\n",
    "    ii  graphsurgeon-tf\t8.4.3-1+cuda11.6\tamd64\tGraphSurgeon for TensorRT package\n",
    "    ii  libnvinfer-bin\t\t8.4.3-1+cuda11.6\tamd64\tTensorRT binaries\n",
    "    ii  libnvinfer-dev\t\t8.4.3-1+cuda11.6\tamd64\tTensorRT development libraries and headers\n",
    "    ii  libnvinfer-plugin-dev\t8.4.3-1+cuda11.6\tamd64\tTensorRT plugin libraries\n",
    "    ii  libnvinfer-plugin8\t8.4.3-1+cuda11.6\tamd64\tTensorRT plugin libraries\n",
    "    ii  libnvinfer-samples\t8.4.3-1+cuda11.6\tall\tTensorRT samples\n",
    "    ii  libnvinfer8\t\t8.4.3-1+cuda11.6\tamd64\tTensorRT runtime libraries\n",
    "    ii  libnvonnxparsers-dev\t\t8.4.3-1+cuda11.6\tamd64\tTensorRT ONNX libraries\n",
    "    ii  libnvonnxparsers8\t8.4.3-1+cuda11.6\tamd64\tTensorRT ONNX libraries\n",
    "    ii  libnvparsers-dev\t8.4.3-1+cuda11.6\tamd64\tTensorRT parsers libraries\n",
    "    ii  libnvparsers8\t8.4.3-1+cuda11.6\tamd64\tTensorRT parsers libraries\n",
    "    ii  python3-libnvinfer\t8.4.3-1+cuda11.6\tamd64\tPython 3 bindings for TensorRT\n",
    "    ii  python3-libnvinfer-dev\t8.4.3-1+cuda11.6\tamd64\tPython 3 development package for TensorRT\n",
    "    ii  tensorrt\t\t8.4.3.x-1+cuda11.6 \tamd64\tMeta package of TensorRT\n",
    "    ii  uff-converter-tf\t8.4.3-1+cuda11.6\tamd64\tUFF converter for TensorRT package\n",
    "    ii  onnx-graphsurgeon   8.4.3-1+cuda11.6  amd64 ONNX GraphSurgeon for TensorRT package\n",
    "   ```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
